{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stompy.model.delft.dflow_model as dfm\n",
    "import numpy as np\n",
    "import logging\n",
    "import pandas as pd\n",
    "from matplotlib import dates\n",
    "\n",
    "import xarray as xr\n",
    "from stompy.grid import multi_ugrid\n",
    "from stompy import utils, memoize, filters\n",
    "import os\n",
    "import six\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_database\n",
    "six.moves.reload_module(run_database)\n",
    "all_runs=run_database.all_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common\n",
    "from common import (prechain, his_cache, save_as_layers, load_or_none, name_runs,\n",
    "                    scen_names, slr_names, events, label_events,\n",
    "                   ebb_period,flood_period,ebb_time,spring_ebb_mid,\n",
    "                   spring_flood_mid, spring_ebb, spring_flood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=run_database.select(period='2016long',slr=0.00,flows='impaired')\n",
    "\n",
    "runs['model']=runs.run_dir.apply(lambda rd: dfm.DFlowModel.load(rd))\n",
    "\n",
    "name_runs(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute\n",
      "Writing to export/Base.nc\n",
      "2 chained datasets\n",
      "Geometries match?\n",
      "Compute\n",
      "Writing to export/Low.nc\n",
      "3 chained datasets\n",
      "Geometries match?\n",
      "Geometries match?\n",
      "Compute\n",
      "Writing to export/Medium.nc\n",
      "2 chained datasets\n",
      "Geometries match?\n",
      "Compute\n",
      "Writing to export/High.nc\n"
     ]
    }
   ],
   "source": [
    "for _,run in runs.iterrows():\n",
    "    his_ds=run['model'].his_dataset(chain=True,prechain=prechain)\n",
    "\n",
    "    variables=['time','station_x_coordinate','station_y_coordinate',\n",
    "               'stations', # 'station_id',\n",
    "               'waterlevel','bedlevel', # 'taus',\n",
    "               'depth-averaged_x_velocity','depth-averaged_y_velocity', \n",
    "\n",
    "               'cross_section',\n",
    "               'cross_section_name','cross_section_discharge','cross_section_area',\n",
    "               'cross_section_velocity'\n",
    "               ]\n",
    "    stations=['pch_up','pch_down','lag1','nmc_down','BC3','ch2','bc1',\n",
    "              'nck','bbr','bbrch','pc3','nmp','nmc_up','mid_mouth','mouth_thalweg',\n",
    "              'npc']\n",
    "\n",
    "    ds=his_ds.copy() # shallow\n",
    "\n",
    "    for v in list(ds):\n",
    "        if v not in variables:\n",
    "            del ds[v]\n",
    "    for v in list(ds.coords):\n",
    "        dims=ds[v].dims\n",
    "        if v=='time': continue\n",
    "        if ('laydim' in dims) or ('laydimw' in dims):\n",
    "            del ds[v]\n",
    "            continue\n",
    "        if 'stations' in dims: continue\n",
    "        if 'cross_section' in dims: continue\n",
    "        del ds[v]\n",
    "\n",
    "    del ds['cross_section_name']\n",
    "    del ds['station_name']\n",
    "\n",
    "    ds_sel=ds.sel(stations=stations)\n",
    "    ds_sel.attrs['projection']='EPSG:26910'\n",
    "    ds_sel.attrs['model_run']=run['run_dir']\n",
    "    export_dir='export'\n",
    "    if not os.path.exists(export_dir):\n",
    "        os.makedirs(export_dir)\n",
    "    nc_fn=os.path.join(export_dir,f'{run[\"name\"]}.nc')\n",
    "    print(\"Compute\")\n",
    "    ds_sel_c=ds_sel.compute()\n",
    "    print(f\"Writing to {nc_fn}\")\n",
    "    ds_sel_c.to_netcdf(nc_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48M\r\n",
      "-rw-rw-r-- 1 rustyh rustyh 26M Oct 18 19:43 Base.nc\r\n",
      "-rw-rw-r-- 1 rustyh rustyh 24M Oct 18 20:33 High.nc\r\n",
      "-rw-rw-r-- 1 rustyh rustyh 24M Oct 18 19:59 Low.nc\r\n",
      "-rw-rw-r-- 1 rustyh rustyh 24M Oct 18 20:18 Medium.nc\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
